"""
å®æ—¶æ¨¡å¼Tokenæå–å™¨ - è¾¹æå–è¾¹ä½¿ç”¨
========================================
æœ€ä½³æ–¹æ¡ˆï¼šé¿å…tokenè¿‡æœŸï¼Œå®æ—¶è·å–æ•°æ®

å·¥ä½œæµç¨‹ï¼š
1. æœç´¢ä¸“åˆ© â†’ 2. æå–token â†’ 3. ç«‹å³ä½¿ç”¨tokenè·å–æ•°æ® â†’ 4. ä¸‹ä¸€ä¸ªä¸“åˆ©

ä¼˜åŠ¿ï¼š
Tokenæå–åç«‹å³ä½¿ç”¨ï¼Œ100%é¿å…è¿‡æœŸ
å®æ—¶ä¿å­˜æ•°æ®ï¼Œé˜²æ­¢æ•°æ®ä¸¢å¤±  
è‡ªåŠ¨æ–­ç‚¹ç»­ä¼ 
æˆåŠŸç‡æœ€é«˜
"""

import csv
import json
import time
import random
import os
import re
import sys
import glob
from urllib.parse import parse_qsl, unquote, unquote_plus, urlparse
from bs4 import BeautifulSoup
from batch_token_extractor_optimized_best import BatchTokenExtractor
import requests
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, StaleElementReferenceException, WebDriverException


class RealTimeProcessor(BatchTokenExtractor):
    """å®æ—¶å¤„ç†å™¨ - ç»§æ‰¿Tokenæå–å™¨å¹¶ç«‹å³ä½¿ç”¨"""
    
    def __init__(self, chromedriver_path, username, password):
        super().__init__(chromedriver_path, username, password)
        self.session = requests.Session()
        self.search_success_count = 0  # ç»Ÿè®¡æœç´¢æˆåŠŸæ¬¡æ•°
        self.search_fail_count = 0     # ç»Ÿè®¡æœç´¢å¤±è´¥æ¬¡æ•°
        self.debug_dir = os.path.join(os.getcwd(), "search_debug")
        os.makedirs(self.debug_dir, exist_ok=True)
        self.performance_mode = "fast"
        self.success_streak = 0
        self.last_search_used_fallback = False
        self.fast_mode_trigger = 3
        self.max_speed_samples = 20
        self.speed_stats = {
            "search": [],
            "token": [],
            "fetch": []
        }
        self.timeout_profiles = {
            "fast": {"base": 3.0, "increment": 0.5, "max": 6},
            "normal": {"base": 4.0, "increment": 1.0, "max": 8}
        }
        self.delay_profiles = {
            "fast_success": (0.3, 0.5),
            "normal_success": (0.6, 1.0),
            "fast_failure": (1.5, 2.5),
            "normal_failure": (2.0, 3.5)
        }
        self.rest_profiles = {
            "fast": (1.2, 2.4),
            "normal": (3.0, 5.0)
        }
        self._search_box_cache = None
        # æé€Ÿæ¥å£å·²ç¦ç”¨ - é‡‡ç”¨å…¶ä»–åŠ é€Ÿç­–ç•¥
        self.use_direct_interface = False  # å®Œå…¨ç¦ç”¨æé€Ÿæ¥å£

    def _record_stage_time(self, stage, duration):
        """è®°å½•é˜¶æ®µè€—æ—¶ï¼Œç”¨äºåŠ¨æ€è°ƒå‚"""
        stats = self.speed_stats.get(stage)
        if stats is None:
            return
        stats.append(duration)
        if len(stats) > self.max_speed_samples:
            stats.pop(0)

    def _get_average_stage_time(self, stage):
        """è·å–æŒ‡å®šé˜¶æ®µçš„å¹³å‡è€—æ—¶"""
        stats = self.speed_stats.get(stage)
        if not stats:
            return None
        return sum(stats) / len(stats)

    def _get_timeout_profile(self):
        return self.timeout_profiles.get(self.performance_mode, self.timeout_profiles["normal"])

    def _get_rest_range(self):
        return self.rest_profiles.get(self.performance_mode, self.rest_profiles["normal"])

    def _get_browser_user_agent(self, driver):
        if self._browser_user_agent:
            return self._browser_user_agent
        try:
            ua = driver.execute_script("return navigator.userAgent;")
            if isinstance(ua, str) and ua:
                self._browser_user_agent = ua
            else:
                self._browser_user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        except Exception:
            self._browser_user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        return self._browser_user_agent

    def _iter_decoded_variants(self, value):
        """å¯¹å“åº”å­—ç¬¦ä¸²åšå¤šè½®è§£ç ï¼Œç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„tokenè½½ä½“æ–‡æœ¬"""
        if not isinstance(value, str) or not value:
            return []
        seen = set()
        queue = [value]
        variants = []
        while queue:
            current = queue.pop(0)
            if current in seen:
                continue
            seen.add(current)
            variants.append(current)
            try:
                decoded = unquote(current)
                if decoded not in seen and decoded != current:
                    queue.append(decoded)
            except Exception:
                pass
            try:
                decoded_plus = unquote_plus(current)
                if decoded_plus not in seen and decoded_plus != current:
                    queue.append(decoded_plus)
            except Exception:
                pass
        return variants

    def _get_search_box(self, driver, timeout=4):
        """è¿”å›å¯å¤ç”¨çš„æœç´¢æ¡†å¼•ç”¨"""
        if self._search_box_cache is not None:
            try:
                if self._search_box_cache.is_displayed() and self._search_box_cache.is_enabled():
                    return self._search_box_cache
            except StaleElementReferenceException:
                self._search_box_cache = None
            except Exception:
                self._search_box_cache = None

        search_box = self._locate_search_box(driver, timeout=timeout)
        if search_box:
            self._search_box_cache = search_box
        return search_box

    def _clear_search_box(self, driver, search_box):
        """å¿«é€Ÿæ¸…ç©ºæœç´¢æ¡†å†…å®¹"""
        try:
            driver.execute_script(
                "arguments[0].value=''; arguments[0].dispatchEvent(new Event('input', {bubbles:true}));",
                search_box
            )
        except Exception:
            pass
        try:
            search_box.clear()
        except Exception:
            pass

    def _ensure_on_homepage(self, driver):
        """ç¡®ä¿å½“å‰åœ¨é¦–é¡µä»¥ä¾¿æ‰§è¡Œæœç´¢"""
        try:
            if "incopat.com" not in (driver.current_url or "") or "depthBrowse" in driver.current_url:
                driver.get("https://www.incopat.com/")
                self._wait_for_home_ready(driver)
        except Exception:
            driver.get("https://www.incopat.com/")
            self._wait_for_home_ready(driver)

    def _accelerated_dom_search(self, driver, patent_no, wait_timeout=3):
        """ä¼˜åŒ–çš„DOMæœç´¢ - æé€Ÿæ¨¡å¼ï¼Œæœ€å°åŒ–ç­‰å¾…"""
        try:
            self._ensure_on_homepage(driver)
            search_box = self._get_search_box(driver, timeout=2)
            if not search_box:
                return False

            self._clear_search_box(driver, search_box)
            search_box.send_keys(patent_no)
            search_box.send_keys(Keys.ENTER)
            
            # æé€Ÿè½®è¯¢ - 0.5ç§’ä¸€æ¬¡æ£€æŸ¥ï¼Œæœ€å¤š6æ¬¡ï¼ˆ3ç§’ï¼‰
            for attempt in range(6):
                time.sleep(0.5)
                link, frame_used = self._locate_result_link(driver, patent_no, timeout=0.3)
                if link:
                    opened = self._open_result_link(driver, link, frame_used, wait_timeout)
                    if opened:
                        self.last_search_used_fallback = False
                    return opened
            
            return False
        except Exception:
            return False

    def _capture_direct_search_template(self, driver, patent_no):
        """æ•è·ä¸€æ¬¡çœŸå®æœç´¢çš„ç½‘ç»œè¯·æ±‚ä½œä¸ºæ¨¡æ¿"""
        if self.direct_search_template:
            return
        try:
            logs = driver.get_log('performance')
        except Exception:
            return

        candidate = None
        for entry in reversed(logs):
            try:
                message = json.loads(entry.get('message', '{}'))
                payload = message.get('message', {})
                if payload.get('method') != 'Network.requestWillBeSent':
                    continue
                request = payload.get('params', {}).get('request', {})
                url = request.get('url', '')
                method = request.get('method', 'GET')
                post_data = request.get('postData', '')
                if patent_no not in url and patent_no not in post_data:
                    continue
                if not url.startswith('http'):
                    continue
                try:
                    parsed = urlparse(url)
                    if parsed.hostname and "incopat.com" not in parsed.hostname:
                        continue
                except Exception:
                    continue
                candidate = {
                    "url": url,
                    "method": method,
                    "headers": request.get('headers', {}),
                    "postData": post_data
                }
                break
            except Exception:
                continue

        if not candidate:
            return

        filtered_headers = {}
        for key, value in candidate["headers"].items():
            key_lower = key.lower()
            if key_lower in {"accept", "content-type", "x-requested-with", "origin", "referer"}:
                filtered_headers[key] = value

        url_template = candidate["url"].replace(patent_no, "{PATENT_NO}")
        body_template = None
        if candidate["postData"]:
            body_template = candidate["postData"].replace(patent_no, "{PATENT_NO}")
        elif patent_no not in candidate["url"]:
            return

        self.direct_search_template = {
            "url": url_template,
            "method": candidate["method"],
            "headers": filtered_headers,
            "body_template": body_template
        }
        self.direct_search_failures = 0
        self.direct_search_disabled_until = 0
        print("  âš¡ å·²æ•è·æœç´¢æ¥å£æ¨¡æ¿ï¼Œåç»­å°†ä¼˜å…ˆèµ°æé€Ÿæ¥å£")

    def _direct_fetch_tokens(self, driver, patent_no):
        """å°è¯•é€šè¿‡æ•è·çš„æ¥å£æ¨¡æ¿ç›´æ¥è·å–Token"""
        if patent_no in self.direct_search_blocklist:
            return None
        if not self.direct_search_template:
            return None
        if self.direct_search_disabled_until:
            if time.time() < self.direct_search_disabled_until:
                return None
            self.direct_search_disabled_until = 0
            self.direct_search_failures = 0
        response = None
        reason = None
        source = "browser"

        try:
            response = self._execute_direct_search(driver, patent_no)
        except TimeoutException:
            reason = "è„šæœ¬è¶…æ—¶"
        except WebDriverException as exc:
            message = str(exc)
            if "script timeout" in message.lower():
                reason = "è„šæœ¬è¶…æ—¶"
            else:
                reason = "æ‰§è¡Œå¼‚å¸¸"
                print(f"  âš ï¸ æé€Ÿæ¥å£å¼‚å¸¸: {exc}")
        except Exception as exc:
            reason = "æ‰§è¡Œå¼‚å¸¸"
            print(f"  âš ï¸ æé€Ÿæ¥å£å¼‚å¸¸: {exc}")

        if response is None and reason is None:
            reason = "æ— å“åº”"

        if response is not None:
            if response.get('error'):
                reason = response['error']
            elif not response.get('ok'):
                status = response.get('status')
                reason = f"çŠ¶æ€ç {status}" if status else "è¯·æ±‚å¤±è´¥"

        if reason:
            print(f"  âš ï¸ æé€Ÿæ¥å£(æµè§ˆå™¨)å¤±è´¥ (åŸå› : {reason})ï¼Œå°è¯•Pythonç›´è¿...")
            fallback_response = self._execute_direct_search_via_requests(driver, patent_no)
            if fallback_response and fallback_response.get('ok'):
                response = fallback_response
                source = fallback_response.get('source', 'requests')
                reason = None
            else:
                if fallback_response:
                    if fallback_response.get('error'):
                        reason = fallback_response.get('error')
                    elif not fallback_response.get('ok'):
                        status = fallback_response.get('status')
                        if status:
                            reason = f"çŠ¶æ€ç {status}"
                    if fallback_response.get('text'):
                        self._save_direct_response_debug(patent_no, fallback_response.get('text'), 'requests_fail')
                if reason:
                    self._register_direct_search_failure(reason, patent_no)
                    return None

        try:
            tokens = self._parse_search_response_for_tokens(
                response.get('text', ''),
                response.get('contentType', '')
            )
            if tokens:
                tag = " (Pythonè¯·æ±‚)" if source != "browser" else ""
                print(f"  âš¡ æé€Ÿæ¥å£å‘½ä¸­ç»“æœ{tag}")
                self.last_search_used_fallback = False
                self.direct_search_failures = 0
                self.direct_search_disabled_until = 0
                return tokens
            else:
                self._save_direct_response_debug(patent_no, response.get('text', ''), f"no_tokens_{source}")
        except Exception as exc:
            self._register_direct_search_failure("è§£æå¤±è´¥", patent_no)
            print(f"  âš ï¸ æé€Ÿæ¥å£è§£æå¼‚å¸¸: {exc}")
            self._save_direct_response_debug(patent_no, response.get('text', ''), 'parse_exception')
            return None
        self._register_direct_search_failure("æœªè§£æåˆ°Token", patent_no)
        return None

    def _register_direct_search_failure(self, reason, patent_no=None):
        self.direct_search_failures += 1
        reason_text = reason or "æœªçŸ¥åŸå› "
        if self.direct_search_failures >= 2 and reason_text in {"è§£æå¤±è´¥", "æœªè§£æåˆ°Token"}:
            self.direct_search_template = None
            print("  â„¹ï¸ å·²æ¸…é™¤æé€Ÿæ¥å£æ¨¡æ¿ï¼Œç­‰å¾…é‡æ–°æ•è·æ›´å‡†ç¡®çš„è¯·æ±‚")
        if patent_no and reason_text in {"è§£æå¤±è´¥", "æœªè§£æåˆ°Token"}:
            if patent_no not in self.direct_search_blocklist:
                self.direct_search_blocklist.add(patent_no)
                print(f"  â„¹ï¸ å·²å¯¹ {patent_no} ç¦ç”¨æé€Ÿæ¥å£ï¼Œåç»­ç›´æ¥ä½¿ç”¨å¸¸è§„æµç¨‹")
        if self.direct_search_failures >= 3:
            cooldown = max(180, self.direct_search_timeout * 10)
            self.direct_search_disabled_until = time.time() + cooldown
            print(f"  âš ï¸ æé€Ÿæ¥å£è¿ç»­å¤±è´¥{self.direct_search_failures}æ¬¡ï¼Œæš‚åœ{cooldown:.0f}ç§’åå†å°è¯• (åŸå› : {reason_text})")
        else:
            print(f"  âš ï¸ æé€Ÿæ¥å£å¤±è´¥ (åŸå› : {reason_text})ï¼Œåˆ‡æ¢åˆ°å¸¸è§„æµç¨‹ (ç´¯è®¡{self.direct_search_failures})")

    def _execute_direct_search(self, driver, patent_no):
        template = self.direct_search_template
        if not template:
            return None

        url = template["url"].replace("{PATENT_NO}", patent_no)
        body = template["body_template"]
        if body is not None:
            body = body.replace("{PATENT_NO}", patent_no)

        fetch_args = {
            "url": url,
            "method": template.get("method", "POST"),
            "body": body,
            "headers": template.get("headers", {}),
            "timeout": self.direct_search_timeout * 1000
        }

        script = """
            const done = arguments[0];
            const cfg = arguments[1] || {};
            const controller = new AbortController();
            const timeout = setTimeout(() => controller.abort(), cfg.timeout || 6000);
            const options = {
                method: cfg.method || 'POST',
                headers: cfg.headers || {},
                credentials: 'include',
                signal: controller.signal
            };
            if (cfg.body !== undefined && cfg.body !== null) {
                options.body = cfg.body;
            }
            fetch(cfg.url, options).then(async (response) => {
                const contentType = response.headers.get('content-type') || '';
                const text = await response.text();
                done({ ok: response.ok, status: response.status, text, contentType });
            }).catch((error) => {
                const message = error && error.message ? error.message : String(error);
                done({ ok: false, error: message });
            }).finally(() => {
                clearTimeout(timeout);
            });
        """

        return driver.execute_async_script(script, fetch_args)

    def _execute_direct_search_via_requests(self, driver, patent_no):
        template = self.direct_search_template
        if not template:
            return None

        url = template["url"].replace("{PATENT_NO}", patent_no)
        body = template["body_template"]
        if body is not None:
            body = body.replace("{PATENT_NO}", patent_no)

        method = template.get("method", "POST").upper()
        headers = dict(template.get("headers") or {})
        header_keys_lower = {key.lower(): key for key in headers.keys()}

        referer = driver.current_url
        if referer and "referer" not in header_keys_lower:
            headers["Referer"] = referer

        user_agent = self._get_browser_user_agent(driver)
        if user_agent and "user-agent" not in header_keys_lower:
            headers["User-Agent"] = user_agent

        if "accept" not in header_keys_lower:
            headers["Accept"] = "application/json, text/plain, */*"

        if body and method in {"POST", "PUT", "PATCH"}:
            if "content-type" not in header_keys_lower:
                headers["Content-Type"] = "application/x-www-form-urlencoded; charset=UTF-8"

        cookie_items = []
        try:
            for cookie in driver.get_cookies():
                name = cookie.get('name')
                value = cookie.get('value')
                if name and value:
                    cookie_items.append(f"{name}={value}")
        except Exception:
            pass
        if cookie_items:
            headers["Cookie"] = "; ".join(cookie_items)

        params = None
        data = None
        if method == "GET" and body:
            try:
                params = {k: v for k, v in parse_qsl(body)}
            except Exception:
                params = None
        elif body is not None:
            data = body

        try:
            response = self.session.request(
                method,
                url,
                headers=headers,
                params=params,
                data=data,
                timeout=self.direct_search_timeout,
                allow_redirects=True
            )
        except Exception as exc:
            return {"ok": False, "error": str(exc), "source": "requests"}

        return {
            "ok": response.ok,
            "status": response.status_code,
            "text": response.text,
            "contentType": response.headers.get('Content-Type', ''),
            "source": "requests"
        }

    def _save_direct_response_debug(self, patent_no, text, tag):
        try:
            if not text:
                return
            debug_dir = os.path.join(self.debug_dir, "direct_interface")
            os.makedirs(debug_dir, exist_ok=True)
            safe_patent = re.sub(r"[^0-9A-Za-z]", "_", patent_no)
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            filename = f"{safe_patent}_{tag}_{timestamp}.txt"
            path = os.path.join(debug_dir, filename)
            with open(path, "w", encoding="utf-8") as f:
                f.write(text)
        except Exception:
            pass

    def _parse_search_response_for_tokens(self, text, content_type):
        if not text:
            return None

        content_type = (content_type or "").lower()
        candidates = self._iter_decoded_variants(text)

        # 1) JSONè§£æï¼ˆåŒ…æ‹¬åµŒå¥—JSONå­—ç¬¦ä¸²ï¼‰
        for candidate in candidates:
            if "json" in content_type or candidate.strip().startswith(('{', '[')):
                try:
                    json_payload = json.loads(candidate)
                    tokens = self._extract_tokens_from_json(json_payload)
                    if tokens:
                        return tokens
                except Exception:
                    continue

        # 2) æŸ¥æ‰¾JSONå­—æ®µä¸­çš„body/queryString
        for candidate in candidates:
            try:
                json_payload = json.loads(candidate)
                if isinstance(json_payload, dict):
                    possible_fields = []
                    for key in ('body', 'data', 'params', 'postData'):
                        if key in json_payload:
                            possible_fields.append(json_payload[key])
                    for field in possible_fields:
                        if isinstance(field, str):
                            nested_candidates = self._iter_decoded_variants(field)
                            for nested in nested_candidates:
                                token_map = self._extract_tokens_from_query_string(nested)
                                if token_map:
                                    return token_map
            except Exception:
                continue

        # 3) ç›´æ¥ä»å­—ç¬¦ä¸²ä¸­è§£æ query string å½¢å¼
        for candidate in candidates:
            token_map = self._extract_tokens_from_query_string(candidate)
            if token_map:
                return token_map

        # 4) é€šç”¨æ­£åˆ™å…œåº•
        regex_candidates = candidates + [text]
        pattern = re.compile(r"(?:\"|')(pnk|folderFlag|oid)(?:\"|')\s*[:=]\s*(?:\"|')([^\"']+)")
        for candidate in regex_candidates:
            matches = pattern.findall(candidate)
            token_map = {key: value for key, value in matches}
            if {'pnk', 'folderFlag', 'oid'}.issubset(token_map.keys()):
                return token_map

        return None

    def _extract_tokens_from_json(self, payload):
        if isinstance(payload, dict):
            if {'pnk', 'folderFlag', 'oid'}.issubset(payload.keys()):
                return {
                    'pnk': payload.get('pnk', ''),
                    'folderFlag': payload.get('folderFlag', ''),
                    'oid': payload.get('oid', '')
                }
            for value in payload.values():
                result = self._extract_tokens_from_json(value)
                if result:
                    return result
        elif isinstance(payload, list):
            for item in payload:
                result = self._extract_tokens_from_json(item)
                if result:
                    return result
        elif isinstance(payload, str):
            try:
                nested = json.loads(payload)
                if nested != payload:
                    return self._extract_tokens_from_json(nested)
            except Exception:
                pass
        return None

    def _extract_tokens_from_query_string(self, candidate):
        if not candidate or not isinstance(candidate, str):
            return None
        lowered = candidate.lower()
        if 'pnk' not in lowered or 'oid' not in lowered:
            return None
        pairs = {}
        try:
            for variant in self._iter_decoded_variants(candidate):
                for part in re.split(r'[?&#\s]', variant):
                    if 'pnk=' in part or 'folderflag=' in part or 'oid=' in part:
                        for sub in part.split('&'):
                            if '=' not in sub:
                                continue
                            key, value = sub.split('=', 1)
                            key = key.strip()
                            if key in {'pnk', 'folderFlag', 'oid'} and value:
                                pairs[key] = value
                if {'pnk', 'folderFlag', 'oid'}.issubset(pairs.keys()):
                    break
        except Exception:
            return None
        if not {'pnk', 'folderFlag', 'oid'}.issubset(pairs.keys()):
            return None
        def _decode(val):
            if not isinstance(val, str):
                return ''
            decoded = val
            for _ in range(3):
                try:
                    new_val = unquote(decoded)
                    if new_val == decoded:
                        break
                    decoded = new_val
                except Exception:
                    break
            return decoded

        return {
            'pnk': _decode(pairs.get('pnk', '')),
            'oid': _decode(pairs.get('oid', ''))
        }
    
    def extract_tokens_from_network(self, driver, patent_no=None):
        """é‡å†™çˆ¶ç±»æ–¹æ³• - ä½¿ç”¨é«˜æ•ˆçš„pnkæå–æ–¹æ³•ï¼ˆexistsPn â†’ init2 â†’ regexï¼‰
        
        Args:
            driver: Selenium WebDriverå®ä¾‹
            patent_no: ä¸“åˆ©å·ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™å°è¯•ä»URLæå–ï¼‰
        """
        try:
            print("  ğŸ” ä½¿ç”¨é«˜æ•ˆæ–¹æ³•æå–pnk...")
            
            # è·å–ä¸“åˆ©å·
            pub_no = patent_no
            
            # å¦‚æœæ²¡æœ‰æä¾›ä¸“åˆ©å·ï¼Œå°è¯•ä»URLä¸­æå–
            if not pub_no:
                current_url = driver.current_url
                # ä»URLä¸­æå–ä¸“åˆ©å·
                if "searchBody=" in current_url:
                    import urllib.parse as urlparse
                    parsed = urlparse.urlparse(current_url)
                    params = urlparse.parse_qs(parsed.query)
                    search_body = params.get('searchBody', [''])[0]
                    if search_body:
                        pub_no = search_body.strip()
            
            # ç›´æ¥è°ƒç”¨çˆ¶ç±»çš„é«˜æ•ˆpnkæå–æ–¹æ³•
            pnk = self._extract_pnk_from_page(driver, pub_no)
            
            if pnk:
                print(f"  âœ“ æˆåŠŸæå–pnk")
                return {'pnk': pnk}
            else:
                print(f"  âŒ æœªèƒ½æå–åˆ°pnk")
                return None
            
        except Exception as e:
            print(f"  âœ— Tokenæå–å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _parse_form_data(self, data):
        """è§£æè¡¨å•æ•°æ®ï¼Œæå–pnk
        
        æ–°APIåªéœ€è¦pnkå‚æ•°ï¼š{"pnk":"xxx"}
        """
        if not data:
            return None
        
        try:
            # JSONæ ¼å¼è§£æï¼ˆæ–°çš„baseInfoæ¥å£ï¼‰
            if isinstance(data, str):
                # å°è¯•JSONæ ¼å¼
                if data.strip().startswith('{'):
                    try:
                        json_data = json.loads(data)
                        if 'pnk' in json_data:
                            # åªè¿”å›pnk
                            return {'pnk': json_data['pnk']}
                    except json.JSONDecodeError:
                        pass
                
                # å°è¯•URLç¼–ç æ ¼å¼ï¼ˆå…¼å®¹æ—§æ ¼å¼ï¼‰
                if '=' in data:
                    params = {}
                    for pair in data.split('&'):
                        if '=' in pair:
                            key, value = pair.split('=', 1)
                            params[key] = unquote(value)
                    
                    # åªè¿”å›pnk
                    if 'pnk' in params:
                        return {'pnk': params['pnk']}
            
            return None
        except Exception as e:
            print(f"  è§£æè¡¨å•æ•°æ®å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def fetch_details_immediately(self, tokens, driver, patent_no):
        """æå–tokenåç«‹å³è·å–è¯¦ç»†ä¿¡æ¯ - ä½¿ç”¨æ–°APIæ¥å£
        
        æ–°APIåªéœ€è¦pnkå‚æ•°
        """
        try:
            print(f"  ï¿½ ç«‹å³è·å–è¯¦ç»†ä¿¡æ¯...")
            
            # æå–pnk
            pnk = tokens.get('pnk', '')
            if not pnk:
                print(f"  âš ï¸ pnkä¸ºç©ºï¼Œæ— æ³•ç»§ç»­")
                return None
            
            print(f"  ä½¿ç”¨pnk: {pnk[:20]}...")
            
            # æ„å»ºrequests sessionå¤ç”¨æµè§ˆå™¨cookies
            session = requests.Session()
            for cookie in driver.get_cookies():
                session.cookies.set(cookie['name'], cookie['value'])
            
            headers = {
                "Content-Type": "application/json",
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                "Referer": driver.current_url,
                "Origin": "https://www.incopat.com"
            }
            
            # API 1: getPatentCommonInfo - åªéœ€è¦pnk
            api_url = "https://www.incopat.com/detailNew/getPatentCommonInfo"
            print(f"  â†’ è°ƒç”¨getPatentCommonInfo API...")
            response = session.post(api_url, json={"pnk": pnk}, headers=headers, timeout=10)
            
            if response.status_code != 200:
                print(f"  âš ï¸ APIå“åº”çŠ¶æ€ç : {response.status_code}")
                return None
                
            result = response.json()
            if not result.get('status'):
                print(f"  âš ï¸ APIè¿”å›å¤±è´¥: {result}")
                return None
            
            common_data = result.get('data', {})
            pt = common_data.get('pt', '')  # ä¸“åˆ©ç±»å‹ä»£ç 
            an = common_data.get('an', '')  # ç”³è¯·å·
            
            # ptæ˜ å°„
            type_map = {"1": "å‘æ˜ç”³è¯·", "2": "å®ç”¨æ–°å‹", "3": "å¤–è§‚è®¾è®¡", "4": "å‘æ˜æˆæƒ"}
            patent_type = type_map.get(pt, "")
            
            print(f"  âœ“ ä¸“åˆ©ç±»å‹: {patent_type}, ç”³è¯·å·: {an}")
            
            # API 2: baseInfo - åªéœ€è¦pnk
            api_url2 = "https://www.incopat.com/detailNew/baseInfo"
            print(f"  â†’ è°ƒç”¨baseInfo API...")
            response2 = session.post(api_url2, json={"pnk": pnk}, headers=headers, timeout=10)
            
            if response2.status_code != 200:
                print(f"  âš ï¸ baseInfoå“åº”çŠ¶æ€ç : {response2.status_code}")
                return None
                
            result2 = response2.json()
            if not result2.get('status'):
                print(f"  âš ï¸ baseInfoè¿”å›å¤±è´¥: {result2}")
                return None
            
            # è·å–æ•°æ® - baseInfoè¿”å›çš„æ˜¯JSONæ ¼å¼
            data = result2.get('data', {})
            
            if not data or not isinstance(data, dict):
                print(f"  âš ï¸ baseInfoè¿”å›æ•°æ®æ ¼å¼é”™è¯¯")
                return None
            
            print(f"  âœ“ è·å–åˆ°JSONæ•°æ®")
            
            # è°ƒè¯•ï¼šæ‰“å°æ•°æ®çš„ä¸€äº›å…³é”®å­—æ®µ
            print(f"  è°ƒè¯•ï¼šJSONæ•°æ®å­—æ®µ = {list(data.keys())}")
            print(f"  è°ƒè¯•ï¼šin_orå­—æ®µ = '{data.get('in_or', 'æœªæ‰¾åˆ°')}'")
            print(f"  è°ƒè¯•ï¼šapRootå­—æ®µ = {data.get('apRoot', 'æœªæ‰¾åˆ°')}")
            
            # ä»JSONæ•°æ®ä¸­æå–è¯¦ç»†ä¿¡æ¯
            details = self.parse_patent_json_for_details(
                data, 
                patent_no,
                patent_type,
                an.replace('CN', '') if an.startswith('CN') else an
            )
            
            print(f"  âœ“ æ•°æ®è·å–å®Œæˆ")
            return details
                
        except Exception as e:
            print(f"  âŒ è·å–è¯¦ç»†ä¿¡æ¯å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def parse_patent_json_for_details(self, data, patent_no, patent_type, application_number):
        """ä»JSONæ•°æ®ä¸­è§£æä¸“åˆ©è¯¦ç»†ä¿¡æ¯ - é€‚é…æ–°APIçš„JSONè¿”å›æ ¼å¼
        
        Args:
            data: baseInfoè¿”å›çš„JSONæ•°æ®
            patent_no: ä¸“åˆ©å·
            patent_type: ä¸“åˆ©ç±»å‹ï¼ˆå·²ä»APIè·å–ï¼‰
            application_number: ç”³è¯·å·ï¼ˆå·²ä»APIè·å–ï¼Œå·²å»CNå‰ç¼€ï¼‰
        """
        def is_organization(applicant_name):
            """åˆ¤æ–­ç”³è¯·äººæ˜¯å¦ä¸ºä¼ä¸š/æœºæ„"""
            if not applicant_name:
                return False
            
            org_keywords = [
                'æœ‰é™å…¬å¸', 'è‚¡ä»½æœ‰é™å…¬å¸', 'æœ‰é™è´£ä»»å…¬å¸', 'å…¬å¸', 'é›†å›¢', 'è‚¡ä»½', 
                'ä¼ä¸š', 'å‚', 'å·¥å‚', 'åˆ¶é€ ', 'ç§‘æŠ€', 'æŠ€æœ¯', 'å·¥ä¸š', 'å®ä¸š',
                'æ§è‚¡', 'æŠ•èµ„', 'è´¸æ˜“', 'å•†è´¸', 'ç”µå­', 'ä¿¡æ¯', 'ç½‘ç»œ', 'è½¯ä»¶',
                'å¤§å­¦', 'å­¦é™¢', 'ç ”ç©¶æ‰€', 'ç ”ç©¶é™¢', 'ç ”ç©¶ä¸­å¿ƒ', 'å®éªŒå®¤', 'ä¸­å¿ƒ', 
                'å­¦æ ¡', 'é™¢æ ¡', 'é™¢', 'æ‰€', 'æ ¡', 'åŒ»é™¢',
                'Limited', 'Ltd', 'Inc', 'Corp', 'Corporation', 'Company', 'Co', 
                'Group', 'Enterprise', 'Industries', 'Industrial', 'Manufacturing', 
                'Technology', 'Technologies', 'Systems', 'Solutions', 'Services',
                'International', 'Global', 'Worldwide', 'Holdings', 'Partners',
                'University', 'College', 'Institute', 'Laboratory', 'Lab', 
                'Research', 'Center', 'Centre', 'Academy', 'School', 'Hospital',
                'GmbH', 'AG', 'KGaA', 'KG', 'SE', 'SA', 'SAS', 'SARL', 'BV', 'NV',
            ]
            
            for keyword in org_keywords:
                if keyword in applicant_name:
                    return True
            
            import re
            if re.search(r'\b[A-Z]{2,}\b', applicant_name):
                return True
            if any(symbol in applicant_name for symbol in ['&', 'Â·', 'ï¼', 'â€”', '-']):
                return True
            if re.search(r'\d+$', applicant_name.strip()):
                return True
            
            clean_name = applicant_name.strip()
            if (clean_name.isupper() and 3 <= len(clean_name) <= 12 and 
                clean_name.isalpha() and not any(char in clean_name for char in [' ', '-', '.'])):
                return True
            
            known_companies = {
                'snecma', 'safran', 'airbus', 'boeing', 'thales', 'nokia', 'samsung', 
                'sony', 'panasonic', 'toshiba', 'hitachi', 'mitsubishi', 'toyota',
                'basf', 'bayer', 'siemens', 'volkswagen', 'bmw', 'mercedes',
            }
            if clean_name.lower() in known_companies:
                return True
            
            return False
        
        # ä»JSONä¸­æå–å„å­—æ®µ - åŸºäºçœŸå®APIç»“æ„
        examiner = ""
        first_applicant = ""
        application_date = ""
        inventors = ""
        abstract = ""
        first_claim = ""
        
        # è°ƒè¯•è¾“å‡ºï¼šæ˜¾ç¤ºJSONæ•°æ®çš„é¡¶çº§å­—æ®µ
        if isinstance(data, dict):
            print(f"è°ƒè¯•ï¼šJSONæ•°æ®é¡¶çº§å­—æ®µ = {list(data.keys())}")
        
        # 1. æå–ç”³è¯·æ—¥ - ä»axisSortMapä¸­æå–å¹¶å»æ‰-å·
        axis_sort_map = data.get('axisSortMap', {})
        for date_key, date_info in axis_sort_map.items():
            if isinstance(date_info, dict) and date_info.get('axisName') == 'ç”³è¯·æ—¥':
                axis_date = date_info.get('axisDate', '')
                if axis_date:
                    # å»æ‰-å·
                    application_date = axis_date.replace('-', '')
                    print(f"è°ƒè¯•ï¼šç”³è¯·æ—¥æœŸ = '{application_date}'")
                    break
        
        # 2. æå–å‘æ˜äºº - ä» bibliographicItems.in_or
        biblio_items = data.get('bibliographicItems', {})
        if isinstance(biblio_items, dict):
            inventors = biblio_items.get('in_or', '')
            print(f"è°ƒè¯•ï¼šå‘æ˜äºº = '{inventors}'")
        
        # 3. æå–ç¬¬ä¸€ç”³è¯·äºº(ä¼ä¸š/æœºæ„) - ä» bibliographicItems.apRoot[0]
        if isinstance(biblio_items, dict):
            ap_root = biblio_items.get('apRoot', [])
            if isinstance(ap_root, list) and len(ap_root) > 0:
                first_app = ap_root[0]
                if first_app and is_organization(first_app):
                    first_applicant = first_app
            print(f"è°ƒè¯•ï¼šç¬¬ä¸€ç”³è¯·äºº = '{first_applicant}'")
        
        # 4. æå–æ‘˜è¦ - ä» summaryInformation.ab_cn
        summary_info = data.get('summaryInformation', {})
        if isinstance(summary_info, dict):
            abstract = summary_info.get('ab_cn', '')
            print(f"è°ƒè¯•ï¼šæ‘˜è¦é•¿åº¦ = {len(abstract)}")
        
        # 5. æå–ç¬¬ä¸€æƒåˆ©è¦æ±‚ - ä» firstClaim.first_claim_or (åªè¦ä¸­æ–‡ç‰ˆï¼Œä¸è¦è‹±æ–‡)
        first_claim_data = data.get('firstClaim', {})
        if isinstance(first_claim_data, dict):
            first_claim = first_claim_data.get('first_claim_or', '')
            print(f"è°ƒè¯•ï¼šç¬¬ä¸€æƒåˆ©è¦æ±‚é•¿åº¦ = {len(first_claim)}")
        
        # 6. æå–å®¡æŸ¥å‘˜ - ä»otherBibliographicItemsä¸­æŸ¥æ‰¾
        other_biblio = data.get('otherBibliographicItems', [])
        if isinstance(other_biblio, list):
            for item in other_biblio:
                if isinstance(item, dict):
                    field = item.get('field', '')
                    name = item.get('name', '')
                    value = item.get('value', '')
                    if name == 'å®¡æŸ¥å‘˜' and value:
                        examiner = value
                        print(f"è°ƒè¯•ï¼šå®¡æŸ¥å‘˜ = '{examiner}'")
                        break
        
        # å¦‚æœè¿˜æ²¡æœ‰å®¡æŸ¥å‘˜ä¿¡æ¯ä¸”æ˜¯å‘æ˜ç”³è¯·ï¼Œå°è¯•ä»PDFæ–‡ä»¶åæå–
        if not examiner and patent_type == 'å‘æ˜ç”³è¯·':
            examiner = self.find_examiner_from_pdf_files(patent_no, patent_type)
        
        return {
            "patent_no": patent_no,
            "patent_type": patent_type,
            "application_date": application_date,
            "application_number": application_number,
            "inventors": inventors,
            "first_applicant": first_applicant,
            "abstract": abstract,
            "examiner": examiner,
            "first_claim": first_claim,
        }
    
    def find_examiner_from_pdf_files(self, patent_no, patent_type):
        """
        ä»æœ¬åœ°pdfsæ–‡ä»¶å¤¹ä¸­æŸ¥æ‰¾å®¡æŸ¥å‘˜ä¿¡æ¯
        åªæœ‰å½“ä¸“åˆ©ç±»å‹ä¸ºå‘æ˜ç”³è¯·æ—¶æ‰æŸ¥æ‰¾
        
        Args:
            patent_no: ä¸“åˆ©å·(å…¬å¼€å·ï¼Œå¦‚CN1790643A)
            patent_type: ä¸“åˆ©ç±»å‹
            
        Returns:
            str: å®¡æŸ¥å‘˜å§“åï¼Œæœªæ‰¾åˆ°åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        # å¿…é¡»æ˜¯"å‘æ˜ç”³è¯·"
        if not patent_type or patent_type != 'å‘æ˜ç”³è¯·':
            return ""
        
        # pdfsæ–‡ä»¶å¤¹è·¯å¾„
        pdfs_folder = 'pdfs'
        
        if not os.path.exists(pdfs_folder):
            return ""
        
        # æ„é€ æœç´¢æ¨¡å¼ï¼šä¸“åˆ©å·_*.pdfï¼ˆåŒ¹é…ä¸“åˆ©å·è€Œä¸æ˜¯ç”³è¯·å·ï¼‰
        search_pattern = os.path.join(pdfs_folder, f"{patent_no}_*.pdf")
        
        # æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶
        matching_files = glob.glob(search_pattern)
        
        if matching_files:
            # å–ç¬¬ä¸€ä¸ªåŒ¹é…çš„æ–‡ä»¶
            pdf_file = matching_files[0]
            filename = os.path.basename(pdf_file)
            
            # ä»æ–‡ä»¶åä¸­æå–å®¡æŸ¥å‘˜å§“å
            # æ–‡ä»¶åæ ¼å¼: ä¸“åˆ©å·_å®¡æŸ¥å‘˜å§“å.pdf
            try:
                # å»æ‰.pdfæ‰©å±•å
                name_part = filename[:-4]
                # æŒ‰_åˆ†å‰²ï¼Œå–æœ€åä¸€éƒ¨åˆ†ä½œä¸ºå®¡æŸ¥å‘˜å§“å
                parts = name_part.split('_')
                if len(parts) >= 2:
                    examiner_name = parts[-1]  # å–æœ€åä¸€éƒ¨åˆ†
                    print(f"     ä»PDFæ–‡ä»¶æå–å®¡æŸ¥å‘˜: {examiner_name}")
                    return examiner_name
            except Exception as e:
                pass
        
        return ""
    
    def parse_patent_html_for_details(self, html, patent_no, patent_type, application_number):
        """è§£æä¸“åˆ©HTMLæ•°æ®è·å–è¯¦ç»†ä¿¡æ¯ - é…åˆæ–°APIä½¿ç”¨
        
        Args:
            html: baseInfoTabè¿”å›çš„HTML
            patent_no: ä¸“åˆ©å·
            patent_type: ä¸“åˆ©ç±»å‹ï¼ˆå·²ä»APIè·å–ï¼‰
            application_number: ç”³è¯·å·ï¼ˆå·²ä»APIè·å–ï¼Œå·²å»CNå‰ç¼€ï¼‰
        """
        soup = BeautifulSoup(html, "html.parser")
        
        def td_after(label):
            td = soup.find("td", string=label)
            return td.find_next_sibling("td").get_text(strip=True) if td else ""
        
        def is_organization(applicant_name):
            """åˆ¤æ–­ç”³è¯·äººæ˜¯å¦ä¸ºä¼ä¸š/æœºæ„(å®Œæ•´ç‰ˆ)"""
            if not applicant_name:
                return False
            
            # ä¼ä¸š/æœºæ„å…³é”®è¯(å®Œæ•´åˆ—è¡¨)
            org_keywords = [
                'æœ‰é™å…¬å¸', 'è‚¡ä»½æœ‰é™å…¬å¸', 'æœ‰é™è´£ä»»å…¬å¸', 'å…¬å¸', 'é›†å›¢', 'è‚¡ä»½', 
                'ä¼ä¸š', 'å‚', 'å·¥å‚', 'åˆ¶é€ ', 'ç§‘æŠ€', 'æŠ€æœ¯', 'å·¥ä¸š', 'å®ä¸š',
                'æ§è‚¡', 'æŠ•èµ„', 'è´¸æ˜“', 'å•†è´¸', 'ç”µå­', 'ä¿¡æ¯', 'ç½‘ç»œ', 'è½¯ä»¶',
                'å¤§å­¦', 'å­¦é™¢', 'ç ”ç©¶æ‰€', 'ç ”ç©¶é™¢', 'ç ”ç©¶ä¸­å¿ƒ', 'å®éªŒå®¤', 'ä¸­å¿ƒ', 
                'å­¦æ ¡', 'é™¢æ ¡', 'é™¢', 'æ‰€', 'æ ¡', 'åŒ»é™¢',
                'Limited', 'Ltd', 'Inc', 'Corp', 'Corporation', 'Company', 'Co', 
                'Group', 'Enterprise', 'Industries', 'Industrial', 'Manufacturing', 
                'Technology', 'Technologies', 'Systems', 'Solutions', 'Services',
                'International', 'Global', 'Worldwide', 'Holdings', 'Partners',
                'University', 'College', 'Institute', 'Laboratory', 'Lab', 
                'Research', 'Center', 'Centre', 'Academy', 'School', 'Hospital',
                'GmbH', 'AG', 'KGaA', 'KG', 'SE', 'SA', 'SAS', 'SARL', 'BV', 'NV',
            ]
            
            for keyword in org_keywords:
                if keyword in applicant_name:
                    return True
            
            # é¢å¤–çš„ä¼ä¸šåˆ¤æ–­é€»è¾‘
            import re
            if re.search(r'\b[A-Z]{2,}\b', applicant_name):
                return True
            if any(symbol in applicant_name for symbol in ['&', 'Â·', 'ï¼', 'â€”', '-']):
                return True
            if re.search(r'\d+$', applicant_name.strip()):
                return True
            
            # å•ä¸ªå¤§å†™å•è¯ä¸”é•¿åº¦é€‚ä¸­
            clean_name = applicant_name.strip()
            if (clean_name.isupper() and 3 <= len(clean_name) <= 12 and 
                clean_name.isalpha() and not any(char in clean_name for char in [' ', '-', '.'])):
                return True
            
            # å·²çŸ¥å…¬å¸åå•
            known_companies = {
                'snecma', 'safran', 'airbus', 'boeing', 'thales', 'nokia', 'samsung', 
                'sony', 'panasonic', 'toshiba', 'hitachi', 'mitsubishi', 'toyota',
                'basf', 'bayer', 'siemens', 'volkswagen', 'bmw', 'mercedes',
            }
            if clean_name.lower() in known_companies:
                return True
            
            return False
        
        # ===== æå–å®¡æŸ¥å‘˜(å®Œæ•´ç‰ˆ - ä¸åŸé€»è¾‘ä¸€è‡´) =====
        examiner = ""
        js_data_str = None
        
        # æ–¹æ³•1: ä»JavaScriptå˜é‡detailDataä¸­æå–
        if "detailData" in html:
            patterns = [
                r"var\s+detailData\s*=\s*({[^;]+});",
                r"detailData\s*=\s*({[^;]+});",
                r"var\s+detailData\s*=\s*({.*?})\s*;",
            ]
            
            for pattern in patterns:
                js_match = re.search(pattern, html, re.DOTALL)
                if js_match:
                    js_data_str = js_match.group(1)
                    break
            
            if js_data_str:
                examiner_patterns = [
                    r"'key'\s*:\s*'å®¡æŸ¥å‘˜'\s*,\s*'value'\s*:\s*'([^']+)'",
                    r"'key'\s*:\s*'\\u5BA1\\u67E5\\u5458'\s*,\s*'value'\s*:\s*'([^']+)'"
                ]
                
                for pattern in examiner_patterns:
                    examiner_match = re.search(pattern, js_data_str)
                    if examiner_match:
                        examiner_raw = examiner_match.group(1)
                        try:
                            if '\\u' in examiner_raw:
                                examiner = examiner_raw.encode('utf-8').decode('unicode_escape')
                            else:
                                examiner = examiner_raw
                        except:
                            examiner = examiner_raw
                        break
        
        # æ–¹æ³•2: ä»è¡¨æ ¼ä¸­æŸ¥æ‰¾
        if not examiner:
            for td in soup.find_all("td"):
                if "å®¡æŸ¥å‘˜" in td.get_text(strip=True):
                    next_td = td.find_next_sibling("td")
                    if next_td:
                        examiner = next_td.get_text(strip=True)
                        break
        
        # æ–¹æ³•3: ä»PDFæ–‡ä»¶åæå–(ä»…å‘æ˜ç”³è¯·)
        if not examiner and patent_type == 'å‘æ˜ç”³è¯·':
            pdf_examiner = self.find_examiner_from_pdf_files(patent_no, patent_type)
            if pdf_examiner:
                examiner = pdf_examiner
        
        # ===== æå–ç¬¬ä¸€ç”³è¯·äºº(ä¼ä¸š/æœºæ„) - å®Œæ•´ç‰ˆ =====
        first_applicant = ""
        
        # æ–¹æ³•1: ä»JavaScript detailDataä¸­æå–
        if js_data_str:
            ap_or_patterns = [
                r"'ap_or'\s*:\s*'([^']+)'",
                r"'ap_or'\s*:\s*'([^']*)'",
                r'"ap_or"\s*:\s*"([^"]+)"'
            ]
            
            for pattern in ap_or_patterns:
                ap_or_match = re.search(pattern, js_data_str)
                if ap_or_match:
                    ap_or_raw = ap_or_match.group(1)
                    try:
                        if '\\u' in ap_or_raw:
                            ap_or_decoded = ap_or_raw.encode('utf-8').decode('unicode_escape')
                        else:
                            ap_or_decoded = ap_or_raw
                        
                        applicants = re.split(r'[;ï¼›|]', ap_or_decoded)
                        if applicants:
                            first_applicant_name = applicants[0].strip()
                            if is_organization(first_applicant_name):
                                first_applicant = first_applicant_name
                            break
                    except:
                        applicants = re.split(r'[;ï¼›|]', ap_or_raw)
                        if applicants:
                            first_applicant_name = applicants[0].strip()
                            if is_organization(first_applicant_name):
                                first_applicant = first_applicant_name
                            break
        
        # æ–¹æ³•2: DOMæ–¹æ³•
        if not first_applicant:
            ap_or_td = soup.find("td", id="ap_orTd")
            if ap_or_td:
                first_applicant_div = ap_or_td.find("div", class_="applicant")
                if first_applicant_div:
                    aplink = first_applicant_div.find("a", attrs={"_label": "aplink"})
                    if aplink:
                        applicant_name = aplink.get_text(strip=True)
                        if is_organization(applicant_name):
                            first_applicant = applicant_name
        
        # æ–¹æ³•3: æ­£åˆ™åŒ¹é…
        if not first_applicant:
            pattern = r'ç”³è¯·äºº\(åŸå§‹\).*?<a[^>]*_label=["\']aplink["\'][^>]*>([^<]+)</a>'
            match = re.search(pattern, html, re.DOTALL | re.IGNORECASE)
            if match:
                applicant_name = match.group(1).strip()
                if is_organization(applicant_name):
                    first_applicant = applicant_name
        
        # ===== æå–å…¶ä»–ä¿¡æ¯ =====
        abstract = ""
        abstract_elem = soup.select_one("span.baseInfo_abstract")
        if abstract_elem:
            abstract = abstract_elem.get_text(strip=True)
        
        first_claim = ""
        claim_elem = soup.select_one("p[_id='firstClaimDiv']")
        if claim_elem:
            first_claim = claim_elem.get_text(strip=True)
        
        application_date = td_after("ç”³è¯·æ—¥")
        inventors = td_after("å‘æ˜äºº(åŸå§‹)")
        
        return {
            "patent_no": patent_no,
            "patent_type": patent_type,
            "application_date": application_date,
            "application_number": application_number,
            "inventors": inventors,
            "first_applicant": first_applicant,
            "abstract": abstract,
            "examiner": examiner,
            "first_claim": first_claim,
        }
    
    # ===== æœç´¢ä¿éšœç­–ç•¥ =====
    def search_patent_with_guards(self, driver, patent_no, max_attempts=3):
        """å¢å¼ºç‰ˆæœç´¢ï¼šé›†æˆé‡è¯•ã€å…œåº•æœç´¢å’Œç°åœºè®°å½•"""
        print("  ğŸ›¡ï¸ å¯ç”¨æœç´¢ä¿éšœç­–ç•¥")
        self.last_search_used_fallback = False
        effective_attempts = max_attempts if self.performance_mode != "fast" else max(2, max_attempts - 1)
        if self._primary_search(driver, patent_no):
            return True
        self._record_search_context(driver, patent_no, attempt_tag="primary")
        for attempt in range(2, effective_attempts + 1):
            wait_timeout = self._adaptive_wait_timeout(attempt)
            print(f"  ğŸ” ç¬¬{attempt}æ¬¡å°è¯•ï¼Œå»¶é•¿ç­‰å¾…è‡³{wait_timeout}ç§’")
            success = self._fallback_search_patent(driver, patent_no, wait_timeout=wait_timeout)
            if success:
                self.last_search_used_fallback = True
                return True
            self._record_search_context(driver, patent_no, attempt_tag=f"fallback{attempt-1}")
            self._gentle_backoff(attempt)
        return False

    def _primary_search(self, driver, patent_no):
        """ä¼˜åŒ–åçš„ä¸»æœç´¢æµç¨‹ - ä¸å†ä½¿ç”¨æé€Ÿæ¥å£"""
        # ç›´æ¥ä½¿ç”¨ä¼˜åŒ–çš„DOMæœç´¢
        if self._accelerated_dom_search(driver, patent_no):
            return True

        # å›é€€åˆ°çˆ¶ç±»é€»è¾‘
        success = super().search_patent(driver, patent_no)
        if success:
            return True

        # æœ€åå°è¯•ï¼šåˆ·æ–°åé‡è¯•
        try:
            self._ensure_on_homepage(driver)
            time.sleep(random.uniform(0.4, 0.6))
        except Exception:
            return False

        return super().search_patent(driver, patent_no)

    def _fallback_search_patent(self, driver, patent_no, wait_timeout=8):
        """å…œåº•æœç´¢æµç¨‹ - ä¼˜åŒ–ç‰ˆ"""
        try:
            driver.switch_to.default_content()
        except Exception:
            pass
        try:
            driver.get("https://www.incopat.com/")
            time.sleep(1.0)  # å‡å°‘ç­‰å¾…
            search_box = self._get_search_box(driver)
            if not search_box:
                return False
            self._clear_search_box(driver, search_box)
            search_box.send_keys(patent_no)
            search_box.send_keys(Keys.ENTER)
            time.sleep(0.3)
        except Exception:
            return False
        
        # å¿«é€Ÿè½®è¯¢ç»“æœ
        for attempt in range(int(wait_timeout / 0.5)):
            time.sleep(0.5)
            link, frame_used = self._locate_result_link(driver, patent_no, timeout=0.3)
            if link:
                opened = self._open_result_link(driver, link, frame_used, 3)
                try:
                    driver.switch_to.default_content()
                except:
                    pass
                if opened:
                    self.last_search_used_fallback = True
                return opened
        
        return False

    def _wait_for_home_ready(self, driver, timeout=3):
        """å¿«é€Ÿç­‰å¾…é¦–é¡µå°±ç»ª"""
        try:
            WebDriverWait(driver, timeout).until(
                lambda d: d.execute_script("return document.readyState") == "complete"
            )
        except TimeoutException:
            pass

    def _locate_search_box(self, driver, timeout=3):
        """æé€Ÿå®šä½æœç´¢æ¡†"""
        # ç›´æ¥å°è¯•æœ€å¸¸è§çš„é€‰æ‹©å™¨
        selectors = [
            "input[placeholder*='è¯·è¾“å…¥']",
            "input[type='text']",
        ]
        for selector in selectors:
            try:
                elements = driver.find_elements(By.CSS_SELECTOR, selector)
                for element in elements:
                    try:
                        if element.is_displayed() and element.is_enabled():
                            return element
                    except:
                        continue
            except:
                continue
        return None

    def _wait_for_result_container(self, driver, timeout):
        """ç­‰å¾…ç»“æœåˆ—è¡¨ã€åŠ è½½æˆ–æ— ç»“æœæç¤ºå‡ºç°"""
        try:
            WebDriverWait(driver, timeout).until(
                EC.any_of(
                    EC.presence_of_element_located((By.CSS_SELECTOR, ".result-list")),
                    EC.presence_of_element_located((By.CSS_SELECTOR, "#resultList")),
                    EC.presence_of_element_located((By.CSS_SELECTOR, "span[name='pnDom']")),
                    EC.presence_of_element_located((By.XPATH, "//*[contains(text(),'æœªæ‰¾åˆ°') or contains(text(),'æ²¡æœ‰æ‰¾åˆ°')]"))
                )
            )
            return True
        except TimeoutException:
            return False

    def _adaptive_wait_timeout(self, attempt):
        """æ ¹æ®æ€§èƒ½æ¨¡å¼ä¸å°è¯•æ¬¡æ•°åŠ¨æ€å†³å®šç­‰å¾…æ—¶é—´"""
        profile = self._get_timeout_profile()
        base = profile["base"]
        increment = profile["increment"]
        max_timeout = profile["max"]

        avg_search = self._get_average_stage_time("search")
        if avg_search and self.performance_mode == "fast":
            if avg_search <= 8:
                base = max(3.5, base - 1.0)
            elif avg_search >= 12:
                base = min(base + 1.5, max_timeout)

        return min(max_timeout, base + (attempt - 1) * increment)

    def _locate_result_link(self, driver, patent_no, timeout):
        """å¿«é€Ÿå®šä½ç»“æœé“¾æ¥ - ä¼˜åŒ–ç‰ˆ"""
        # ä¼˜å…ˆåœ¨ä¸»é¡µé¢æŸ¥æ‰¾
        normalized_target = re.sub(r"\s+", "", patent_no or "").upper()
        try:
            pn_spans = driver.find_elements(By.CSS_SELECTOR, "span[name='pnDom']")
            for span in pn_spans:
                try:
                    span_text = re.sub(r"\s+", "", (span.text or "")).upper()
                    if span_text == normalized_target:
                        link = span.find_element(By.XPATH, "ancestor::a[1]")
                        return link, None
                except Exception:
                    continue

            # å›é€€åˆ°é€šç”¨é€‰æ‹©å™¨
            selectors = [
                "a[onclick*='openDetail']",
                "a[href*='openDetail']",
                "a[onclick*='openDetailedInfo']",
                "a[href*='openDetailedInfo']",
            ]
            for selector in selectors:
                for link in driver.find_elements(By.CSS_SELECTOR, selector):
                    try:
                        link_text = re.sub(r"\s+", "", (link.text or "")).upper()
                        if normalized_target in link_text:
                            return link, None
                    except Exception:
                        continue
        except Exception:
            pass
        
        # å¦‚æœä¸»é¡µé¢æ²¡æ‰¾åˆ°ï¼Œå¿«é€Ÿæ£€æŸ¥iframe
        frame_used = None
        try:
            frames = driver.find_elements(By.TAG_NAME, "iframe")
            for frame in frames[:2]:  # åªæ£€æŸ¥å‰2ä¸ªiframe
                try:
                    driver.switch_to.frame(frame)
                    pn_spans = driver.find_elements(By.CSS_SELECTOR, "span[name='pnDom']")
                    for span in pn_spans:
                        try:
                            span_text = re.sub(r"\s+", "", (span.text or "")).upper()
                            if span_text == normalized_target:
                                link = span.find_element(By.XPATH, "ancestor::a[1]")
                                frame_used = frame.get_attribute("id") or "iframe"
                                return link, frame_used
                        except Exception:
                            continue

                    for selector in selectors:
                        for link in driver.find_elements(By.CSS_SELECTOR, selector):
                            try:
                                link_text = re.sub(r"\s+", "", (link.text or "")).upper()
                                if normalized_target in link_text:
                                    frame_used = frame.get_attribute("id") or "iframe"
                                    return link, frame_used
                            except Exception:
                                continue
                except:
                    pass
                finally:
                    driver.switch_to.default_content()
        except:
            pass
        
        return None, None

    def _open_result_link(self, driver, link, frame_used, wait_timeout):
        """å¿«é€Ÿæ‰“å¼€ç»“æœé“¾æ¥"""
        main_window = driver.current_window_handle
        existing_windows = set(driver.window_handles)
        
        try:
            driver.execute_script("arguments[0].click();", link)
        except Exception:
            try:
                link.click()
            except Exception:
                return False
        
        # å¿«é€Ÿæ£€æµ‹æ–°çª—å£æˆ–URLå˜åŒ–
        for _ in range(10):  # æœ€å¤šç­‰2ç§’ï¼ˆæ¯æ¬¡0.2ç§’ï¼‰
            time.sleep(0.2)
            new_windows = list(set(driver.window_handles) - existing_windows)
            if new_windows:
                driver.switch_to.window(new_windows[-1])
                break
            if "depthBrowse" in driver.current_url:
                break
        else:
            # è¶…æ—¶åä»æ£€æŸ¥ä¸€æ¬¡URL
            if "depthBrowse" not in driver.current_url:
                return False
        
        if frame_used:
            try:
                driver.switch_to.default_content()
            except:
                pass
        
        return True

    def _record_search_context(self, driver, patent_no, attempt_tag):
        """ä¿å­˜å¤±è´¥æ—¶çš„é¡µé¢ä¸æˆªå›¾ä¾¿äºæ’æŸ¥"""
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        safe_patent = re.sub(r"[^0-9A-Za-z]", "_", patent_no)
        base_name = f"{safe_patent}_{attempt_tag}_{timestamp}"
        html_path = os.path.join(self.debug_dir, f"{base_name}.html")
        screenshot_path = os.path.join(self.debug_dir, f"{base_name}.png")
        try:
            with open(html_path, 'w', encoding='utf-8') as f:
                f.write(driver.page_source)
            print(f"  ğŸ§¾ å·²ä¿å­˜å¤±è´¥é¡µé¢: {html_path}")
        except Exception as exc:
            print(f"  âš ï¸ ä¿å­˜HTMLå¤±è´¥: {exc}")
        try:
            driver.save_screenshot(screenshot_path)
            print(f"  ğŸ“¸ å·²ä¿å­˜æˆªå›¾: {screenshot_path}")
        except Exception as exc:
            print(f"  âš ï¸ ä¿å­˜æˆªå›¾å¤±è´¥: {exc}")

    def _gentle_backoff(self, attempt):
        """é‡è¯•å‰çš„å‹å¥½é€€é¿ï¼Œç¼“è§£èŠ‚æµé£æ§"""
        if self.performance_mode == "fast":
            low, high = self.delay_profiles["fast_failure"]
        else:
            low, high = self.delay_profiles["normal_failure"]
        low += attempt * 0.3
        high += attempt * 0.5
        delay = random.uniform(low, high)
        print(f"  â³ é€€é¿ç­‰å¾… {delay:.1f} ç§’åé‡è¯•")
        time.sleep(delay)

    def _update_performance_profile(self, success, used_fallback):
        """æ ¹æ®æœ€è¿‘è¡¨ç°åˆ‡æ¢æé€Ÿ/ç¨³å¥æ¨¡å¼"""
        if not success:
            if self.performance_mode != "normal":
                print("  ğŸ”„ æ£€æµ‹åˆ°å¤±è´¥ï¼Œåˆ‡å›ç¨³å¥æ¨¡å¼")
            self.performance_mode = "normal"
            self.success_streak = 0
            return
        if used_fallback:
            if self.performance_mode != "normal":
                print("  âš ï¸ ä½¿ç”¨å…œåº•æœç´¢ï¼Œåˆ‡å›ç¨³å¥æ¨¡å¼")
            self.performance_mode = "normal"
            self.success_streak = 0
            return
        self.success_streak += 1
        if self.performance_mode == "normal" and self.success_streak >= self.fast_mode_trigger:
            self.performance_mode = "fast"
            self.success_streak = 0
            print("  ğŸš€ è¿ç»­æˆåŠŸï¼Œåˆ‡æ¢è‡³æé€Ÿæ¨¡å¼")
        elif self.performance_mode == "fast":
            avg_search = self._get_average_stage_time("search")
            if avg_search and avg_search > 12:
                print("  âš ï¸ æé€Ÿæ¨¡å¼ä¸‹æœç´¢åæ…¢ï¼Œå›å½’ç¨³å¥æ¨¡å¼")
                self.performance_mode = "normal"
                self.success_streak = 0

    def _get_adaptive_delay(self, success, consecutive_failures):
        """æ ¹æ®æ¨¡å¼ä¸å½“å‰çŠ¶æ€è¿”å›å¤„ç†é—´éš”"""
        if success:
            key = "fast_success" if self.performance_mode == "fast" else "normal_success"
            low, high = self.delay_profiles[key]
            return random.uniform(low, high)
        if consecutive_failures > 0:
            key = "fast_failure" if self.performance_mode == "fast" else "normal_failure"
            low, high = self.delay_profiles[key]
            adjustment = min(1.5, consecutive_failures * 0.5)
            return random.uniform(low + adjustment, high + adjustment)
        return random.uniform(0.8, 1.6)

    def _print_speed_insights(self):
        avg_search = self._get_average_stage_time("search")
        avg_token = self._get_average_stage_time("token")
        avg_fetch = self._get_average_stage_time("fetch")
        if any(val is not None for val in (avg_search, avg_token, avg_fetch)):
            print("\nâš¡ æ€§èƒ½å¿«ç…§:")
            print(f"   æ¨¡å¼: {self.performance_mode}")
            if avg_search is not None:
                print(f"   å¹³å‡æœç´¢è€—æ—¶: {avg_search:.1f}ç§’")
            if avg_token is not None:
                print(f"   å¹³å‡Tokenæå–è€—æ—¶: {avg_token:.1f}ç§’")
            if avg_fetch is not None:
                print(f"   å¹³å‡è¯¦æƒ…è·å–è€—æ—¶: {avg_fetch:.1f}ç§’")
    
    def process_single_patent_realtime(self, driver, patent_no, skip_search=True):
        """å®æ—¶å¤„ç†å•ä¸ªä¸“åˆ© - æå–tokenåç«‹å³è·å–æ•°æ®ï¼ˆæé€Ÿä¼˜åŒ–ç‰ˆï¼‰
        
        Args:
            driver: Selenium WebDriverå®ä¾‹
            patent_no: ä¸“åˆ©å·
            skip_search: æ˜¯å¦è·³è¿‡æœç´¢ç›´æ¥æå–pnkï¼ˆé»˜è®¤Trueï¼Œæé€Ÿ8-10å€ï¼‰
        """
        start_time = time.time()
        try:
            print(f"\nğŸ” å¤„ç†ä¸“åˆ©: {patent_no}")
            
            search_time = 0
            
            # ğŸš€ æé€Ÿæ¨¡å¼ï¼šè·³è¿‡æœç´¢ï¼Œç›´æ¥æå–pnk
            if skip_search:
                print(f"  ğŸš€ æé€Ÿæ¨¡å¼ï¼šè·³è¿‡æœç´¢ï¼Œç›´æ¥æå–pnk...")
                
                # æ­¥éª¤1: ç›´æ¥æå–pnk
                token_start = time.time()
                pnk = self._extract_pnk_from_page(driver, patent_no)
                
                if not pnk:
                    print(f"  âœ— æœªèƒ½æå–åˆ°pnk")
                    return None
                
                tokens = {'pnk': pnk, 'patent_no': patent_no}
                token_time = time.time() - token_start
                self._record_stage_time("token", token_time)
                print(f"  âœ“ pnkæå–æˆåŠŸ ({token_time:.2f}ç§’)")
                
            else:
                # ä¼ ç»Ÿæ¨¡å¼ï¼šå…ˆæœç´¢å†æå–
                search_start = time.time()
                self.last_search_used_fallback = False
                
                if not self.search_patent_with_guards(driver, patent_no):
                    self.search_fail_count += 1
                    self._update_performance_profile(success=False, used_fallback=False)
                    print(f"  âœ— æœç´¢å¤±è´¥ (ç´¯è®¡å¤±è´¥: {self.search_fail_count})")
                    return None

                search_time = time.time() - search_start
                self.search_success_count += 1
                self._record_stage_time("search", search_time)
                print(f"  âœ“ æœç´¢æˆåŠŸ ({search_time:.1f}ç§’, ç´¯è®¡æˆåŠŸ: {self.search_success_count})")

                # æ­¥éª¤2: æå–token
                token_start = time.time()
                tokens = self.extract_tokens_from_network(driver, patent_no)
                if not tokens:
                    self._update_performance_profile(success=False, used_fallback=self.last_search_used_fallback)
                    print(f"  âœ— æå–tokenå¤±è´¥")
                    return None

                tokens['patent_no'] = patent_no
                token_time = time.time() - token_start
                self._record_stage_time("token", token_time)
                print(f"  âœ“ Tokenæå–æˆåŠŸ ({token_time:.1f}ç§’)")
            
            # æ­¥éª¤2/3: ç«‹å³ä½¿ç”¨tokenè·å–è¯¦ç»†ä¿¡æ¯
            fetch_start = time.time()
            patent_data = self.fetch_details_immediately(tokens, driver, patent_no)
            fetch_time = time.time() - fetch_start
            if patent_data:
                self._record_stage_time("fetch", fetch_time)
            
            if patent_data:
                total_time = time.time() - start_time
                print(f"  âœ“ æ•°æ®è·å–æˆåŠŸ ({fetch_time:.1f}ç§’)")
                
                # æ ¹æ®æ˜¯å¦è·³è¿‡æœç´¢æ˜¾ç¤ºä¸åŒçš„æ—¶é—´åˆ†è§£
                if skip_search:
                    print(f"     æ€»è€—æ—¶: {total_time:.1f}ç§’ (pnkæå–:{token_time:.2f}s + è¯¦æƒ…è·å–:{fetch_time:.1f}s) âš¡âš¡âš¡")
                else:
                    print(f"     æ€»è€—æ—¶: {total_time:.1f}ç§’ (æœç´¢:{search_time:.1f}s + Token:{token_time:.1f}s + è·å–:{fetch_time:.1f}s)")
                
                print(f"     ç±»å‹: {patent_data.get('patent_type', '')}")
                print(f"     ç”³è¯·äºº: {patent_data.get('first_applicant', '(æ— ä¼ä¸šç”³è¯·äºº)')}")
                print(f"     å®¡æŸ¥å‘˜: {patent_data.get('examiner', '(æ— )')}")
                print(f"     å‘æ˜äºº: {patent_data.get('inventors', '')[:30]}...")
                
                # å…³é—­è¯¦æƒ…é¡µçª—å£ï¼ˆæé€Ÿæ¨¡å¼ä¸‹ä¸éœ€è¦ï¼‰
                if not skip_search:
                    try:
                        if len(driver.window_handles) > 1:
                            driver.close()
                            driver.switch_to.window(driver.window_handles[0])
                    except:
                        pass
                
                if not skip_search:
                    self._update_performance_profile(success=True, used_fallback=self.last_search_used_fallback)
                return patent_data
            else:
                if not skip_search:
                    self._update_performance_profile(success=False, used_fallback=self.last_search_used_fallback)
                print(f"  âœ— æ•°æ®è·å–å¤±è´¥")
                return None
                
        except Exception as e:
            if not skip_search:
                self._update_performance_profile(success=False, used_fallback=self.last_search_used_fallback)
            print(f"  âœ— å¤„ç†å¼‚å¸¸: {e}")
            return None
    
    def process_single_patent_no_search(self, driver, patent_no):
        """å®æ—¶å¤„ç†å•ä¸ªä¸“åˆ© - æé€Ÿç‰ˆï¼ˆæ— éœ€æœç´¢ï¼‰
        
        æµç¨‹ï¼šç›´æ¥æå–pnk â†’ è·å–è¯¦ç»†ä¿¡æ¯
        ç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•ï¼Œè·³è¿‡æœç´¢ç¯èŠ‚ï¼Œæé€Ÿ8-10å€
        """
        start_time = time.time()
        try:
            print(f"\nğŸ” å¤„ç†ä¸“åˆ©: {patent_no}")
            
            # ğŸš€ æ­¥éª¤1: ç›´æ¥æå–pnkï¼ˆæ— éœ€æœç´¢ï¼‰
            print(f"  ğŸš€ è·³è¿‡æœç´¢ï¼Œç›´æ¥æå–pnk...")
            token_start = time.time()
            
            pnk = self._extract_pnk_from_page(driver, patent_no)
            
            if not pnk:
                print(f"  âœ— æœªèƒ½æå–åˆ°pnk")
                return None
            
            tokens = {'pnk': pnk, 'patent_no': patent_no}
            token_time = time.time() - token_start
            print(f"  âœ“ pnkæå–æˆåŠŸ ({token_time:.2f}ç§’)")
            
            # ğŸš€ æ­¥éª¤2: ç«‹å³ä½¿ç”¨pnkè·å–è¯¦ç»†ä¿¡æ¯
            fetch_start = time.time()
            patent_data = self.fetch_details_immediately(tokens, driver, patent_no)
            fetch_time = time.time() - fetch_start
            
            if patent_data:
                total_time = time.time() - start_time
                print(f"  âœ“ æ•°æ®è·å–æˆåŠŸ ({fetch_time:.1f}ç§’)")
                print(f"     æ€»è€—æ—¶: {total_time:.1f}ç§’ (pnkæå–:{token_time:.2f}s + è¯¦æƒ…è·å–:{fetch_time:.1f}s)")
                print(f"     ç±»å‹: {patent_data.get('patent_type', '')}")
                print(f"     ç”³è¯·äºº: {patent_data.get('first_applicant', '(æ— ä¼ä¸šç”³è¯·äºº)')}")
                print(f"     å®¡æŸ¥å‘˜: {patent_data.get('examiner', '(æ— )')}")
                
                return patent_data
            else:
                print(f"  âœ— æ•°æ®è·å–å¤±è´¥")
                return None
                
        except Exception as e:
            print(f"  âœ— å¤„ç†å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def process_batch_realtime(self, patent_list, output_file="realtime_patent_details.json", skip_unavailable=True, skip_search=True):
        """æ‰¹é‡å¤„ç†ä¸“åˆ© - å®æ—¶æ¨¡å¼ï¼ˆæé€Ÿç‰ˆï¼‰
        
        Args:
            patent_list: ä¸“åˆ©å·åˆ—è¡¨
            output_file: è¾“å‡ºæ–‡ä»¶å
            skip_unavailable: æ˜¯å¦è‡ªåŠ¨è·³è¿‡ä¸å¯ç”¨çš„ä¸“åˆ©ï¼ˆé»˜è®¤Trueï¼‰
            skip_search: æ˜¯å¦è·³è¿‡æœç´¢ç›´æ¥æå–pnkï¼ˆé»˜è®¤Trueï¼Œæé€Ÿ8-10å€ï¼‰âš¡
        """
        print(f"ğŸš€ å¼€å§‹å®æ—¶å¤„ç† {len(patent_list)} ä¸ªä¸“åˆ©")
        print("=" * 70)
        
        if skip_search:
            print("ğŸ“‹ å·¥ä½œæµç¨‹ï¼ˆğŸ”¥ æé€Ÿæ¨¡å¼ - æ— éœ€æœç´¢ï¼‰:")
            print("   1ï¸âƒ£  ç›´æ¥æå–pnk âš¡âš¡âš¡")
            print("   2ï¸âƒ£  ç«‹å³è·å–è¯¦ç»†æ•°æ® âš¡")
            print("   3ï¸âƒ£  å®æ—¶ä¿å­˜ç»“æœ ğŸ’¾")
            print("   4ï¸âƒ£  ä¸‹ä¸€ä¸ªä¸“åˆ©")
            print("\nğŸ¯ æé€Ÿæ¨¡å¼ä¼˜åŠ¿:")
            print("   â€¢ è·³è¿‡æœç´¢ç¯èŠ‚ï¼Œæé€Ÿ 8-10å€ ğŸš€")
            print("   â€¢ æ¯ä¸ªä¸“åˆ©ä»…éœ€ 2-3ç§’ âš¡")
            print("   â€¢ ç›´æ¥è°ƒç”¨APIæå–pnk ğŸ’¨")
        else:
            print("ğŸ“‹ å·¥ä½œæµç¨‹ï¼ˆä¼ ç»Ÿæ¨¡å¼ï¼‰:")
            print("   1ï¸âƒ£  æœç´¢ä¸“åˆ© âš¡")
            print("   2ï¸âƒ£  æå–Token âš¡")
            print("   3ï¸âƒ£  ç«‹å³ä½¿ç”¨Tokenè·å–æ•°æ® âš¡")
            print("   4ï¸âƒ£  å®æ—¶ä¿å­˜ç»“æœ ğŸ’¾")
            print("   5ï¸âƒ£  ä¸‹ä¸€ä¸ªä¸“åˆ©")
            print("\nğŸ¯ ä¼˜åŒ–äº®ç‚¹:")
            print("   â€¢ å‡å°‘50%ç­‰å¾…æ—¶é—´")
            print("   â€¢ æ™ºèƒ½å…ƒç´ å®šä½")
            print("   â€¢ å¿«é€Ÿé‡è¯•æœºåˆ¶")
            print(f"   â€¢ è‡ªé€‚åº”æ€§èƒ½æ¨¡å¼ (å½“å‰: {self.performance_mode})")
        
        if skip_unavailable:
            print("   â€¢ è‡ªåŠ¨è¯†åˆ«ä¸å¯ç”¨ä¸“åˆ© ğŸ”")
        print("=" * 70)
        
        # è¯»å–å·²å®Œæˆçš„ä¸“åˆ©
        completed_patents = set()
        existing_results = []
        
        if os.path.exists(output_file):
            try:
                with open(output_file, 'r', encoding='utf-8') as f:
                    existing_results = json.load(f)
                    completed_patents = {item['patent_no'] for item in existing_results}
                print(f"ğŸ“‚ å‘ç°å·²å®Œæˆ {len(completed_patents)} ä¸ªä¸“åˆ©ï¼Œå°†è·³è¿‡")
            except:
                pass
        
        # è¿‡æ»¤æœªå®Œæˆçš„ä¸“åˆ©
        remaining_patents = [p for p in patent_list if p not in completed_patents]
        
        if not remaining_patents:
            print("âœ… æ‰€æœ‰ä¸“åˆ©å·²å®Œæˆ!")
            return []
        
        print(f"ğŸ“‹ å‰©ä½™ {len(remaining_patents)} ä¸ªä¸“åˆ©å¾…å¤„ç†\n")
        
        results = existing_results.copy()
        failed_patents = []
        unavailable_patents = []  # è®°å½•ä¸å¯ç”¨çš„ä¸“åˆ©
        consecutive_failures = 0
        consecutive_not_found = 0  # è¿ç»­æœªæ‰¾åˆ°è®¡æ•°
        
        driver = None
        batch_start_time = time.time()
        
        try:
            driver = self.create_driver()
            
            if not self.login(driver):
                print("âŒ ç™»å½•å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
                return []
            
            for i, patent_no in enumerate(remaining_patents, 1):
                print(f"\n{'='*70}")
                print(f"[{i}/{len(remaining_patents)}] è¿›åº¦: {i/len(remaining_patents)*100:.1f}%")
                
                # ğŸ†• æ£€æµ‹è¿ç»­å¤šæ¬¡"æœªæ‰¾åˆ°"å¯èƒ½æ„å‘³ç€è¿™æ‰¹ä¸“åˆ©ä¸å¯ç”¨
                if skip_unavailable and consecutive_not_found >= 5:
                    print(f"  âš ï¸ æ£€æµ‹åˆ°è¿ç»­{consecutive_not_found}æ¬¡æœªæ‰¾åˆ°ä¸“åˆ©")
                    print(f"  ğŸ’¡ å»ºè®®: è¿™äº›ä¸“åˆ©å¯èƒ½åœ¨æ•°æ®åº“ä¸­ä¸å­˜åœ¨")
                    print(f"  ğŸ“ è‡ªåŠ¨æ ‡è®°ä¸ºä¸å¯ç”¨å¹¶è·³è¿‡")
                    unavailable_patents.append(patent_no)
                    consecutive_not_found = 0
                    continue
                
                # è¿ç»­å¤±è´¥è¶…è¿‡3æ¬¡ï¼Œé‡å¯æµè§ˆå™¨
                if consecutive_failures >= 3:
                    print(f"  âš ï¸ æ£€æµ‹åˆ°è¿ç»­{consecutive_failures}æ¬¡å¤±è´¥ï¼Œé‡å¯æµè§ˆå™¨...")
                    try:
                        driver.quit()
                    except:
                        pass
                    
                    time.sleep(2)
                    driver = self.create_driver()
                    
                    if not self.login(driver):
                        print("  âŒ é‡æ–°ç™»å½•å¤±è´¥")
                        break
                    
                    consecutive_failures = 0
                
                # å®æ—¶å¤„ç†ï¼ˆæé€Ÿä¼˜åŒ–ç‰ˆï¼‰
                patent_data = self.process_single_patent_realtime(driver, patent_no, skip_search=skip_search)
                
                if patent_data:
                    results.append(patent_data)
                    consecutive_failures = 0
                    consecutive_not_found = 0  # é‡ç½®æœªæ‰¾åˆ°è®¡æ•°
                    
                    # å®æ—¶ä¿å­˜
                    self.save_results_realtime(results, output_file)
                    print(f"  ğŸ’¾ å·²ä¿å­˜ ({len(results)}/{len(remaining_patents)})")
                else:
                    # åˆ¤æ–­å¤±è´¥ç±»å‹
                    if self.search_fail_count > len(failed_patents):
                        # è¿™æ˜¯æœç´¢å¤±è´¥ï¼ˆæœªæ‰¾åˆ°ï¼‰
                        consecutive_not_found += 1
                        print(f"  âš ï¸ æœªæ‰¾åˆ°ä¸“åˆ© (è¿ç»­æœªæ‰¾åˆ°: {consecutive_not_found})")
                    else:
                        # è¿™æ˜¯å…¶ä»–ç±»å‹å¤±è´¥
                        consecutive_not_found = 0
                    
                    consecutive_failures += 1
                    failed_patents.append(patent_no)
                    print(f"  âŒ å¤„ç†å¤±è´¥ (è¿ç»­å¤±è´¥: {consecutive_failures})")
                
                # ğŸš€ æ™ºèƒ½å»¶è¿Ÿï¼šæ ¹æ®æˆåŠŸç‡åŠ¨æ€è°ƒæ•´
                if i < len(remaining_patents):
                    delay = self._get_adaptive_delay(success=patent_data is not None, consecutive_failures=consecutive_failures)
                    time.sleep(delay)
                
                # æ¯10ä¸ªä¸“åˆ©ä¼‘æ¯
                if i % 10 == 0 and i < len(remaining_patents):
                    rest_low, rest_high = self._get_rest_range()
                    rest_time = random.uniform(rest_low, rest_high)
                    print(f"\n  ğŸ˜´ å¤„ç†äº†{i}ä¸ªä¸“åˆ©ï¼Œä¼‘æ¯{rest_time:.1f}ç§’...")
                    time.sleep(rest_time)
                    
                    # æ¯20ä¸ªåˆ·æ–°ä¼šè¯
                    if i % 20 == 0:
                        print(f"  ğŸ”„ åˆ·æ–°ä¼šè¯ä¿æŒæ´»è·ƒ...")
                        try:
                            # å…³é—­æ‰€æœ‰è¯¦æƒ…é¡µçª—å£ï¼Œå›åˆ°ä¸»çª—å£
                            if len(driver.window_handles) > 1:
                                for handle in driver.window_handles[1:]:
                                    driver.switch_to.window(handle)
                                    driver.close()
                                driver.switch_to.window(driver.window_handles[0])
                            
                            # ç®€å•åˆ·æ–°é¦–é¡µè€Œä¸é‡æ–°ç™»å½•(ä¿æŒsession)
                            driver.get("https://www.incopat.com/")
                            time.sleep(1.5)  # å‡å°‘ç­‰å¾…æ—¶é—´
                            
                            # éªŒè¯æ˜¯å¦ä»åœ¨ç™»å½•çŠ¶æ€
                            try:
                                # å¦‚æœèƒ½æ‰¾åˆ°ç™»å½•æŒ‰é’®ï¼Œè¯´æ˜sessionå¤±æ•ˆäº†
                                driver.find_element(By.CLASS_NAME, "loginBtn")
                                print(f"  âš ï¸ æ£€æµ‹åˆ°ä¼šè¯å¤±æ•ˆï¼Œå°è¯•é‡æ–°ç™»å½•...")
                                if not self.login(driver):
                                    print(f"  âš ï¸ é‡æ–°ç™»å½•å¤±è´¥ï¼Œç»§ç»­å°è¯•")
                            except:
                                # æ‰¾ä¸åˆ°ç™»å½•æŒ‰é’®ï¼Œè¯´æ˜ä»åœ¨ç™»å½•çŠ¶æ€
                                print(f"  âœ“ ä¼šè¯ä»ç„¶æœ‰æ•ˆ")
                        except Exception as e:
                            print(f"  âš ï¸ ä¼šè¯åˆ·æ–°å¼‚å¸¸: {e}ï¼Œç»§ç»­å¤„ç†")
                
                # è¾“å‡ºç»Ÿè®¡
                if i % 10 == 0:
                    elapsed_time = time.time() - batch_start_time
                    avg_time = elapsed_time / i
                    success_rate = len(results) / i * 100
                    estimated_remaining = avg_time * (len(remaining_patents) - i) / 60
                    
                    print(f"\nğŸ“Š å½“å‰ç»Ÿè®¡:")
                    print(f"   æˆåŠŸ: {len(results)} | å¤±è´¥: {len(failed_patents)}")
                    print(f"   æˆåŠŸç‡: {success_rate:.1f}%")
                    print(f"   å¹³å‡é€Ÿåº¦: {avg_time:.1f}ç§’/ä¸ª")
                    print(f"   é¢„è®¡å‰©ä½™æ—¶é—´: {estimated_remaining:.1f}åˆ†é’Ÿ")
                    print(f"   æœç´¢æˆåŠŸç‡: {self.search_success_count}/{self.search_success_count + self.search_fail_count}")
                    self._print_speed_insights()
            
            # ä¿å­˜å¤±è´¥åˆ—è¡¨
            if failed_patents:
                failed_file = output_file.replace('.json', '_failed.txt')
                with open(failed_file, 'w', encoding='utf-8') as f:
                    f.write('\n'.join(failed_patents))
                print(f"\nâš ï¸ å¤±è´¥ä¸“åˆ©å·²ä¿å­˜åˆ°: {failed_file}")
            
            # ä¿å­˜ä¸å¯ç”¨ä¸“åˆ©åˆ—è¡¨
            if unavailable_patents:
                unavailable_file = output_file.replace('.json', '_unavailable.txt')
                with open(unavailable_file, 'w', encoding='utf-8') as f:
                    f.write('\n'.join(unavailable_patents))
                print(f"ğŸ“ ä¸å¯ç”¨ä¸“åˆ©å·²ä¿å­˜åˆ°: {unavailable_file}")
            
            total_time = time.time() - batch_start_time
            print(f"\n{'='*70}")
            print(f"ğŸ‰ å¤„ç†å®Œæˆ!")
            print(f"   æˆåŠŸ: {len(results)}/{len(remaining_patents)}")
            print(f"   å¤±è´¥: {len(failed_patents)}/{len(remaining_patents)}")
            if unavailable_patents:
                print(f"   ä¸å¯ç”¨: {len(unavailable_patents)}/{len(remaining_patents)}")
            print(f"   æˆåŠŸç‡: {len(results)/len(remaining_patents)*100:.1f}%")
            print(f"   æ€»è€—æ—¶: {total_time/60:.1f}åˆ†é’Ÿ")
            print(f"   å¹³å‡é€Ÿåº¦: {total_time/len(remaining_patents):.1f}ç§’/ä¸ª")
            print(f"   ç»“æœæ–‡ä»¶: {output_file}")
            
            # ç»™å‡ºå»ºè®®
            if len(unavailable_patents) > 0 or len(failed_patents) > len(results) * 0.3:
                print(f"\nğŸ’¡ å»ºè®®:")
                print(f"   è¿è¡Œ python check_patent_availability.py")
                print(f"   å¯ä»¥é¢„å…ˆæ£€æŸ¥ä¸“åˆ©å¯ç”¨æ€§ï¼Œé¿å…æµªè´¹æ—¶é—´")
            
        except Exception as e:
            print(f"\nâŒ æ‰¹é‡å¤„ç†å¼‚å¸¸: {e}")
        
        finally:
            if driver:
                try:
                    driver.quit()
                except:
                    pass
        
        return results
    
    def save_results_realtime(self, results, output_file):
        """å®æ—¶ä¿å­˜ç»“æœ"""
        # ä¿å­˜JSON
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜CSV
        if results:
            csv_file = output_file.replace('.json', '.csv')
            fieldnames = results[0].keys()
            with open(csv_file, 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(results)


def main():
    """ä¸»å‡½æ•°"""
    CHROMEDRIVER_PATH = "D:/BaiduNetdiskDownload/chromedriver-win64/chromedriver.exe"
    USERNAME = "cxip"
    PASSWORD = "193845"
    
    # è¯»å–ä¸“åˆ©åˆ—è¡¨
    all_patent_list = []
    try:
        with open("patent_list.csv", "r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            all_patent_list = [row["patent_no"].strip() for row in reader if row.get("patent_no")]
    except FileNotFoundError:
        print("æœªæ‰¾åˆ° patent_list.csv æ–‡ä»¶")
        return
    
    if not all_patent_list:
        print("ä¸“åˆ©åˆ—è¡¨ä¸ºç©º")
        return
    
    print("\n" + "=" * 70)
    print("å®æ—¶æ¨¡å¼ - è¾¹æå–Tokenè¾¹è·å–æ•°æ®")
    print("=" * 70)
    print(f"æ€»ä¸“åˆ©æ•°é‡: {len(all_patent_list)}")
    print("\næ ¸å¿ƒä¼˜åŠ¿:")
    print("   â€¢ Tokenæå–åç«‹å³ä½¿ç”¨ï¼Œå½»åº•é¿å…è¿‡æœŸ ")
    print("   â€¢ æ¯å®Œæˆä¸€ä¸ªå°±ä¿å­˜ï¼Œæ•°æ®é›¶ä¸¢å¤± ")
    print("   â€¢ æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œéšæ—¶å¯ä¸­æ–­ ")
    print("   â€¢ æˆåŠŸç‡æœ€é«˜ï¼Œæ¨èæ–¹æ¡ˆ ")
    print("=" * 70)
    
    processor = RealTimeProcessor(
        chromedriver_path=CHROMEDRIVER_PATH,
        username=USERNAME,
        password=PASSWORD
    )
    
    processor.process_batch_realtime(
        patent_list=all_patent_list,
        output_file="realtime_patent_details.json"
    )


if __name__ == "__main__":
    main()
